from nltk.tokenize import sent_tokenize

text = "I love NLP. It is amazing! Let's learn more."

# Sentence tokenization
sentences = sent_tokenize(text)

print("Sentence Tokens:", sentences)
